{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadi Heidari Rad - 810197011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI - Naive Bayse Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Data from file, and allocating 80% of it to Training data and rest 20% to Testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>چون می‌رود این کشتی سرگشته که آخر</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>که همین بود حد امکانش</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ارادتی بنما تا سعادتی ببری</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>خدا را زین معما پرده بردار</td>\n",
       "      <td>hafez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>گویی که در برابر چشمم مصوری</td>\n",
       "      <td>saadi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  label\n",
       "0  چون می‌رود این کشتی سرگشته که آخر  hafez\n",
       "1              که همین بود حد امکانش  saadi\n",
       "2         ارادتی بنما تا سعادتی ببری  hafez\n",
       "3         خدا را زین معما پرده بردار  hafez\n",
       "4        گویی که در برابر چشمم مصوری  saadi"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('train_test.csv')\n",
    "\n",
    "# code for randomizing dataset:\n",
    "# data = data.sample(frac = 1)\n",
    "\n",
    "separated_data = np.split(data, [round(len(data) * 0.2)], axis=0)\n",
    "train_data = separated_data[1]\n",
    "test_data = separated_data[0]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating Hafez and Saadi Poems, with the purpose of computing their used words datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hafez_df = train_data[train_data.label != 'saadi']\n",
    "saadi_df = train_data[train_data.label != 'hafez']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Naive bayes formula: $P(c|X) = P(x_1|c)*P(x_2|c)*P(x_3|c)...P(x_n|c)P(c)$ (by also omitting denominator as said in the project description), we need to first calculate $P(Hafez)$ and $P(Saadi)$ within the given dataset, and then calculate probabilty of occurance of each word, in their own dataset of words (which is $P(x_n|c)$) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(hafez) : 0.4030279456645323\n",
      "P(saadi) : 0.5969720543354676\n"
     ]
    }
   ],
   "source": [
    "def p(favorable, total):\n",
    "    return favorable / total\n",
    "\n",
    "p_hafez = p(len(hafez_df) , len(train_data))\n",
    "p_saadi = p(len(saadi_df) , len(train_data))\n",
    "print(\"P(hafez) : \" + str( p_hafez ))\n",
    "print(\"P(saadi) : \" + str( p_saadi ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting words of each single line poem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hafez_poems = hafez_df['text']\n",
    "hafez_poems_splitted = []\n",
    "for each in hafez_poems:\n",
    "    hafez_poems_splitted.append(re.split(' ', each))\n",
    "    \n",
    "saadi_poems = saadi_df['text']\n",
    "saadi_poems_splitted = []\n",
    "for each in saadi_poems:\n",
    "    saadi_poems_splitted.append(re.split(' ', each))\n",
    "\n",
    "whole_train_poems = train_data['text']\n",
    "train_poems_splitted = []\n",
    "for each in whole_train_poems:\n",
    "    train_poems_splitted.append(re.split(' ', each))\n",
    "    \n",
    "test_poems = test_data['text']\n",
    "test_labels = []\n",
    "for each in test_data['label']:\n",
    "    test_labels.append(each)\n",
    "test_poems_splitted = []\n",
    "for each in test_poems:\n",
    "    test_poems_splitted.append(re.split(' ', each))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting each unique words occurrence times in both (Hafez and Saadi) words datasets (and also both put together):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_words_cnt = 0\n",
    "words_freq = {}\n",
    "for poem in train_poems_splitted:\n",
    "    for word in poem:\n",
    "        if word not in words_freq:\n",
    "            words_freq[word] = 1\n",
    "            whole_words_cnt += 1\n",
    "        else:\n",
    "            words_freq[word] += 1\n",
    "            whole_words_cnt += 1\n",
    "            \n",
    "words_freq_cnt = len(words_freq)\n",
    "\n",
    "hafez_words_cnt = 0\n",
    "hafez_words_freq = {}\n",
    "for poem in hafez_poems_splitted:\n",
    "    for word in poem:\n",
    "        if word not in hafez_words_freq:\n",
    "            hafez_words_freq[word] = 1\n",
    "            hafez_words_cnt += 1\n",
    "        else:\n",
    "            hafez_words_freq[word] += 1\n",
    "            hafez_words_cnt += 1\n",
    "\n",
    "saadi_words_cnt = 0\n",
    "saadi_words_freq = {}\n",
    "for poem in saadi_poems_splitted:\n",
    "    for word in poem:\n",
    "        if word not in saadi_words_freq:\n",
    "            saadi_words_freq[word] = 1\n",
    "            saadi_words_cnt += 1\n",
    "        else:\n",
    "            saadi_words_freq[word] += 1\n",
    "            saadi_words_cnt += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider testing some data where you encounter a record (word here) that you haven't had in your trained dataset before. We shouldn't certainly say that the data doesn't belong to that class, because we havent seen the whole available dataset yet obviously, and it might exist while we had just not seen it. So, we assign a very little value to such records in order to prevent the whole expressions probabilty from getting Zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as said above, we use laplace smoothing formula to assign a new $P$ to every previous $P$ by also keeping the weights as before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">$P = \\frac{x_i + \\alpha}{total + \\alpha*d}$</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_i$ and $total$ are respectively number of desired and all possible occurences in a problem, though, assigning $\\alpha = 0$ will lead to the normal $P$ formula. But in practice $\\alpha$ is often chosen as 1. $d$ is also the number of unique words in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_p(favorable, total, alpha, d):\n",
    "    return (favorable + alpha) / (total + alpha*d)\n",
    "\n",
    "def naive_bayes(splitted_poem, alpha):\n",
    "    \n",
    "    global hafez_words_cnt\n",
    "    global saadi_words_cnt\n",
    "    global hafez_words_freq\n",
    "    global saadi_words_freq\n",
    "    global p_hafez\n",
    "    global p_saadi\n",
    "    global words_freq_cnt\n",
    "    \n",
    "    p_is_hafez = p_hafez\n",
    "    for each in splitted_poem:\n",
    "        if each not in hafez_words_freq and each not in saadi_words_freq:\n",
    "            continue\n",
    "        if each in hafez_words_freq:\n",
    "            p_is_hafez *= laplace_p(hafez_words_freq[each] , hafez_words_cnt, alpha, words_freq_cnt)\n",
    "        else:\n",
    "            p_is_hafez *= laplace_p(0 , hafez_words_cnt, alpha, words_freq_cnt)\n",
    "    \n",
    "    p_is_saadi = p_saadi\n",
    "    for each in splitted_poem:\n",
    "        if each not in hafez_words_freq and each not in saadi_words_freq:\n",
    "            continue\n",
    "        if each in saadi_words_freq:\n",
    "            p_is_saadi *= laplace_p(saadi_words_freq[each] , saadi_words_cnt, alpha, words_freq_cnt)\n",
    "        else:\n",
    "            p_is_saadi *= laplace_p(0 , saadi_words_cnt, alpha, words_freq_cnt)\n",
    "    \n",
    "    if p_is_hafez > p_is_saadi:\n",
    "        return \"hafez\"\n",
    "    else:\n",
    "        return \"saadi\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Laplace smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7642412637625658\n",
      "Recall: 0.6559714795008913\n",
      "Precision: 0.7311258278145696\n"
     ]
    }
   ],
   "source": [
    "hafez_cnt = 0\n",
    "for each in test_labels:\n",
    "    if each == 'hafez':\n",
    "        hafez_cnt += 1\n",
    "hit = 0\n",
    "hit_hafez = 0\n",
    "detected_hafez = 0\n",
    "alpha = 0\n",
    "for i in range(0, len(test_poems_splitted)):\n",
    "    detected = naive_bayes(test_poems_splitted[i], alpha)\n",
    "    if detected == 'hafez':\n",
    "        detected_hafez += 1\n",
    "    if detected == test_labels[i]:\n",
    "        hit += 1\n",
    "    if detected == test_labels[i] and detected == 'hafez':\n",
    "        hit_hafez += 1\n",
    "\n",
    "print(\"\\nAccuracy: \" + str(hit/len(test_data)))\n",
    "print(\"Recall: \" + str(hit_hafez/hafez_cnt))\n",
    "print(\"Precision: \" + str(hit_hafez/detected_hafez))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Laplace Smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8054092867400671\n",
      "Recall: 0.6916221033868093\n",
      "Precision: 0.7983539094650206\n"
     ]
    }
   ],
   "source": [
    "hafez_cnt = 0\n",
    "for each in test_labels:\n",
    "    if each == 'hafez':\n",
    "        hafez_cnt += 1\n",
    "hit = 0\n",
    "hit_hafez = 0\n",
    "detected_hafez = 0\n",
    "alpha = 1\n",
    "for i in range(0, len(test_poems_splitted)):\n",
    "    detected = naive_bayes(test_poems_splitted[i], alpha)\n",
    "    if detected == 'hafez':\n",
    "        detected_hafez += 1\n",
    "    if detected == test_labels[i]:\n",
    "        hit += 1\n",
    "    if detected == test_labels[i] and detected == 'hafez':\n",
    "        hit_hafez += 1\n",
    "\n",
    "print(\"\\nAccuracy: \" + str(hit/len(test_data)))\n",
    "print(\"Recall: \" + str(hit_hafez/hafez_cnt))\n",
    "print(\"Precision: \" + str(hit_hafez/detected_hafez))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, it caused all of them to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, outputting evaluate.csv data with their all predicted values into resault.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.read_csv('evaluate.csv')\n",
    "eval_poems = eval_data.text\n",
    "n = len(eval_poems)\n",
    "alpha = 1\n",
    "predictions = []\n",
    "for i in range(0, n):\n",
    "    predictions.append(naive_bayes(eval_poems[i], alpha))\n",
    "tmp = [{'id': i + 1, 'label': label} for i, label in enumerate(predictions)]\n",
    "df = pd.DataFrame(tmp, index=None)\n",
    "# df.head()\n",
    "df.to_csv('resault.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we only consider precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision specifies the number of truly predicted records over all predicted records of a same class. Thus, it does good at recognizing whether all resaults from a predicition is truly detected or not, but it's not good when it comes to recogniznig whether all same classified objects are detected or not. As an example, consider a surgeon who has to remove all cancerous parts of an important body organ like brain, that at the same time all cancerous parts have to be removed and no healthy parts should be. So, by <b>only</b> considering precision, the doctor will be restricted to only remove the parts that he is sort of sure to be canserous, which at a same time, causes recall to decrease. (A trade-off between both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we only consider accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem happens when the dataset we're working with, is biased (imbalance). For example, a dataset with 80% of class A and 20% of class B, if we design a model that always predicts A (!) it will have a 0.8 accuracy. <br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
